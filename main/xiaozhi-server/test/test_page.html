<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>小智服务器测试页面</title>
    <link rel="stylesheet" href="test_page.css">
    <style>
        #fileProtocolWarning {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 9999;
            color: white;
            padding: 20px;
            box-sizing: border-box;
        }

        #fileProtocolWarning h2 {
            color: #ff4d4d;
            margin-bottom: 20px;
        }

        #fileProtocolWarning pre {
            background-color: green;
            font-size: 18px;
            padding: 15px;
            border-radius: 5px;
            font-family: monospace;
            overflow-x: auto;
            margin: 15px 0;
        }

        #fileProtocolWarning button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 10px 2px;
            cursor: pointer;
            border-radius: 4px;
        }

        #fileProtocolWarning button:hover {
            background-color: #45a049;
        }
    </style>
    <script>
        // 检测是否使用file://协议打开
        if (window.location.protocol === 'file:') {
            document.addEventListener('DOMContentLoaded', function () {
                // 创建警告框
                const warningDiv = document.createElement('div');
                warningDiv.id = 'fileProtocolWarning';
                warningDiv.innerHTML = `
                    <h2>⚠️ 警告：请使用HTTP服务器打开此页面</h2>
                    <p>您当前使用的是本地文件方式打开页面（file://协议），这可能导致页面功能异常。</p>
                    <p>您可以使用nginx映射启动测试页面，也可以请按照以下步骤使用python启动测试http服务：</p>
                    <ol>
                        <li>打开命令行终端</li>
                        <li>命令行进入到 xiaozhi-server/test 目录</li>
                        <li>执行以下命令启动HTTP服务器：</li>
                    </ol>
                    <pre>python -m http.server 8006</pre>
                    <p>然后在浏览器中访问：<strong>http://localhost:8006/test_page.html</strong></p>
                `;
                document.body.appendChild(warningDiv);
            });
        }
    </script>
</head>

<body>
    <div class="container">
        <h1>小智服务器测试页面</h1>

        <!-- 环境警告横幅 -->
        <div id="environmentWarning" class="environment-warning">
            <h3>🚨 重要提示：麦克风功能不可用</h3>
            <p><strong>当前环境不支持麦克风和摄像头访问</strong></p>
            <p>Chrome/Edge浏览器要求HTTPS环境或localhost才能使用麦克风功能</p>
            <p>当前访问地址：<strong id="currentUrl"></strong></p>
            
            <div class="solutions">
                <p><strong>解决方案：</strong></p>
                <ul>
                    <li><strong>方案1（推荐）</strong>：配置HTTPS证书，使用 https:// 访问</li>
                    <li><strong>方案2</strong>：将服务器绑定到localhost，使用 localhost:端口 访问</li>
                    <li><strong>方案3（临时）</strong>：Chrome地址栏输入 chrome://flags/#unsafely-treat-insecure-origin-as-secure，添加当前域名</li>
                </ul>
            </div>
        </div>

        <div id="scriptStatus" style="position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);">
            正在加载Opus库...
        </div>

        <!-- 添加配置面板 -->
        <div class="section">
            <h2>
                设备配置
                <span class="device-info">
                    <span>MAC: <strong id="displayMac"></strong></span>
                    <span>客户端: <strong id="displayClient">web_test_client</strong></span>
                </span>
                <button class="toggle-button" id="toggleConfig">编辑</button>
            </h2>
            <div class="config-panel" id="configPanel">
                <div class="control-panel">
                    <div class="config-item">
                        <label for="deviceMac">设备MAC:</label>
                        <input type="text" id="deviceMac" placeholder="设备MAC地址">
                    </div>
                    <div class="config-item">
                        <label for="deviceName">设备名称:</label>
                        <input type="text" id="deviceName" value="Web测试设备" placeholder="设备名称">
                    </div>
                    <div class="config-item">
                        <label for="clientId">客户端ID:</label>
                        <input type="text" id="clientId" value="web_test_client" placeholder="客户端ID">
                    </div>
                    <div class="config-item">
                        <label for="token">认证Token:</label>
                        <input type="text" id="token" value="your-token1" placeholder="认证Token">
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>
                连接信息
                <span class="connection-status">
                    <span>OTA: <span id="otaStatus" class="status">ota未连接</span></span>
                    <span>WS: <span id="connectionStatus" class="status">ws未连接</span></span>
                </span>
            </h2>
            <div class="connection-controls">
                <input type="text" id="otaUrl" value="http://127.0.0.1:8002/xiaozhi/ota/"
                    placeholder="OTA服务器地址，如：http://127.0.0.1:8002/xiaozhi/ota/" />
                <input type="text" id="serverUrl" value="ws://127.0.0.1:8000/xiaozhi/v1/"
                    placeholder="WebSocket服务器地址，如：ws://127.0.0.1:8000/xiaozhi/v1/" />
                <button id="connectButton">连接</button>
                <button id="authTestButton">测试认证</button>
                <button id="micTestButton">测试麦克风</button>
            </div>
        </div>

        <div class="section">
            <div class="tabs">
                <button class="tab active" data-tab="text">文本消息</button>
                <button class="tab" data-tab="voice">语音消息</button>
            </div>

            <div class="tab-content active" id="textTab">
                <div class="message-input">
                    <input type="text" id="messageInput" placeholder="输入消息..." disabled>
                    <button id="sendTextButton" disabled>发送</button>
                </div>
            </div>

            <div class="tab-content" id="voiceTab">
                <div class="audio-controls">
                    <button id="recordButton" class="record-button" disabled>开始录音</button>
                </div>
                <canvas id="audioVisualizer" class="audio-visualizer"></canvas>
            </div>
        </div>

        <div class="section">
            <h2>会话记录</h2>
            <div class="flex-container">
                <div id="conversation" class="conversation"></div>
                <div id="logContainer">
                    <div class="log-entry log-info">准备就绪，请连接服务器开始测试...</div>
                </div>
            </div>
        </div>
    </div>

    <!-- Opus解码库 -->
    <script src="libopus.js"></script>

    <script type="module">
        import { log } from './js/utils/logger.js';
        import { webSocketConnect } from './js/xiaoZhiConnect.js';
        import { checkOpusLoaded, initOpusEncoder } from './js/opus.js';
        import { addMessage } from './js/document.js'
        import BlockingQueue from './js/utils/BlockingQueue.js'
        // 需要加载的脚本列表 - 移除Opus依赖
        const scriptFiles = [];

        // 脚本加载状态
        const scriptStatus = {
            loading: 0,
            loaded: 0,
            failed: 0,
            total: scriptFiles.length
        };

        // 全局变量
        let websocket = null;
        let mediaRecorder = null;
        let audioContext = null;
        let analyser = null;
        let audioChunks = [];
        let isRecording = false;
        let visualizerCanvas = document.getElementById('audioVisualizer');
        let visualizerContext = visualizerCanvas.getContext('2d');
        let audioQueue = [];
        let isPlaying = false;
        let opusDecoder = null; // Opus解码器
        let visualizationRequest = null; // 动画帧请求ID
        let connectionRetryCount = 0;
        const maxRetryAttempts = 3;

        // 音频流缓冲相关
        let audioBuffers = []; // 用于存储接收到的所有音频数据
        let totalAudioSize = 0; // 跟踪累积的音频大小

        let audioBufferQueue = [];     // 存储接收到的音频包
        let isAudioPlaying = false;    // 是否正在播放音频
        const BUFFER_THRESHOLD = 3;    // 缓冲包数量阈值，至少累积3个包再开始播放
        const MIN_AUDIO_DURATION = 0.1; // 最小音频长度(秒)，小于这个长度的音频会被合并
        let streamingContext = null;   // 音频流上下文
        const SAMPLE_RATE = 16000;     // 采样率
        const CHANNELS = 1;            // 声道数
        const FRAME_SIZE = 960;        // 帧大小

        // DOM元素
        const connectButton = document.getElementById('connectButton');
        const serverUrlInput = document.getElementById('serverUrl');
        const connectionStatus = document.getElementById('connectionStatus');
        const messageInput = document.getElementById('messageInput');
        const sendTextButton = document.getElementById('sendTextButton');
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const conversationDiv = document.getElementById('conversation');
        const logContainer = document.getElementById('logContainer');

        function getAudioContextInstance() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE,
                    latencyHint: 'interactive'
                });
                log('创建音频上下文，采样率: ' + SAMPLE_RATE + 'Hz', 'debug');
            }
            return audioContext;
        }

        // 初始化可视化器
        function initVisualizer() {
            visualizerCanvas.width = visualizerCanvas.clientWidth;
            visualizerCanvas.height = visualizerCanvas.clientHeight;
            visualizerContext.fillStyle = '#fafafa';
            visualizerContext.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
        }

        // 绘制音频可视化效果
        function drawVisualizer(dataArray) {
            visualizationRequest = requestAnimationFrame(() => drawVisualizer(dataArray));

            if (!isRecording) return;

            analyser.getByteFrequencyData(dataArray);

            visualizerContext.fillStyle = '#fafafa';
            visualizerContext.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);

            const barWidth = (visualizerCanvas.width / dataArray.length) * 2.5;
            let barHeight;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                barHeight = dataArray[i] / 2;

                visualizerContext.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                visualizerContext.fillRect(x, visualizerCanvas.height - barHeight, barWidth, barHeight);

                x += barWidth + 1;
            }
        }

        const queue = new BlockingQueue();

        // 启动缓存进程
        async function startAudioBuffering() {
            log("开始音频缓冲...", 'info');

            // 先尝试初始化解码器，以便在播放时已准备好
            initOpusDecoder().catch(error => {
                log(`预初始化Opus解码器失败: ${error.message}`, 'warning');
                // 继续缓冲，我们会在播放时再次尝试初始化
            });
            const timeout = 300;
            while (true) {
                // 每次数据空的时候等三条数据
                const packets = await queue.dequeue(
                    3,                       // 至少 3 条
                    timeout,                     // 最多等 300 ms
                    (count) => {             // 超时额外回调
                        log(`缓冲超时，当前缓冲包数: ${count}，开始播放`, 'info');
                    }
                );
                if (packets.length) {
                    log(`已缓冲 ${packets.length} 个音频包，开始播放`, 'info');
                    streamingContext.pushAudioBuffer(packets)
                }
                // 50毫秒里，有多少给多少
                while (true) {
                    const data = await queue.dequeue(99, 50)
                    if (data.length) {
                        streamingContext.pushAudioBuffer(data)
                    } else {
                        break
                    }
                }
            }
        }

        // 播放已缓冲的音频
        async function playBufferedAudio() {
            // 确保Opus解码器已初始化
            try {
                // 确保音频上下文存在
                audioContext = getAudioContextInstance();

                // 确保解码器已初始化
                if (!opusDecoder) {
                    log('初始化Opus解码器...', 'info');
                    try {
                        opusDecoder = await initOpusDecoder();
                        if (!opusDecoder) {
                            throw new Error('解码器初始化失败');
                        }
                        log('Opus解码器初始化成功', 'success');
                    } catch (error) {
                        log('Opus解码器初始化失败: ' + error.message, 'error');
                        isAudioPlaying = false;
                        return;
                    }
                }

                // 创建流式播放上下文
                if (!streamingContext) {
                    streamingContext = {
                        queue: [],          // 已解码的PCM队列。正在播放
                        activeQueue: new BlockingQueue(), // 已解码的PCM队列。准备播放
                        pendingAudioBufferQueue: [],  // 待处理的缓存队列
                        audioBufferQueue: new BlockingQueue(),  // 缓存队列
                        playing: false,     // 是否正在播放
                        endOfStream: false, // 是否收到结束信号
                        source: null,       // 当前音频源
                        totalSamples: 0,    // 累积的总样本数
                        lastPlayTime: 0,    // 上次播放的时间戳


                        // 缓存音频数组
                        pushAudioBuffer: function (item) {
                            this.audioBufferQueue.enqueue(...item)
                        },

                        // 获取需要处理缓存队列，单线程：在audioBufferQueue一直更新的状态下不会出现安全问题
                        getPendingAudioBufferQueue: async function () {
                            // 原子交换 + 清空
                            [this.pendingAudioBufferQueue, this.audioBufferQueue] = [await this.audioBufferQueue.dequeue(), new BlockingQueue()];

                        },
                        // 获取正在播放已解码的PCM队列，单线程：在activeQueue一直更新的状态下不会出现安全问题
                        getQueue: async function (minSamples) {
                            let TepArray = []
                            const num = minSamples - this.queue.length > 0 ? minSamples - this.queue.length : 1;
                            // 原子交换 + 清空
                            [TepArray, this.activeQueue] = [await this.activeQueue.dequeue(num), new BlockingQueue()];
                            this.queue.push(...TepArray)
                        },
                        // 将Opus数据解码为PCM
                        decodeOpusFrames: async function () {
                            if (!opusDecoder) {
                                log('Opus解码器未初始化，无法解码', 'error');
                                return;
                            } else {
                                log('Opus解码器启动', 'info');
                            }

                            while (true) {
                                let decodedSamples = [];
                                for (const frame of this.pendingAudioBufferQueue) {
                                    try {
                                        // 使用Opus解码器解码
                                        const frameData = opusDecoder.decode(frame);
                                        if (frameData && frameData.length > 0) {
                                            // 转换为Float32
                                            const floatData = convertInt16ToFloat32(frameData);
                                            // 使用循环替代展开运算符
                                            for (let i = 0; i < floatData.length; i++) {
                                                decodedSamples.push(floatData[i]);
                                            }
                                        }
                                    } catch (error) {
                                        log("Opus解码失败: " + error.message, 'error');
                                    }
                                }

                                if (decodedSamples.length > 0) {
                                    // 使用循环替代展开运算符
                                    for (let i = 0; i < decodedSamples.length; i++) {
                                        this.activeQueue.enqueue(decodedSamples[i]);
                                    }
                                    this.totalSamples += decodedSamples.length;
                                } else {
                                    log('没有成功解码的样本', 'warning');
                                }
                                await this.getPendingAudioBufferQueue();
                            }
                        },

                        // 开始播放音频
                        startPlaying: async function () {
                            while (true) {
                                // 如果累积了至少0.3秒的音频，开始播放
                                const minSamples = SAMPLE_RATE * MIN_AUDIO_DURATION * 3;
                                if (!this.playing && this.queue.length < minSamples) {
                                    await this.getQueue(minSamples)
                                }
                                this.playing = true;
                                while (this.playing && this.queue.length) {
                                    // 创建新的音频缓冲区
                                    const minPlaySamples = Math.min(this.queue.length, SAMPLE_RATE);
                                    const currentSamples = this.queue.splice(0, minPlaySamples);

                                    const audioBuffer = audioContext.createBuffer(CHANNELS, currentSamples.length, SAMPLE_RATE);
                                    audioBuffer.copyToChannel(new Float32Array(currentSamples), 0);

                                    // 创建音频源
                                    this.source = audioContext.createBufferSource();
                                    this.source.buffer = audioBuffer;

                                    // 创建增益节点用于平滑过渡
                                    const gainNode = audioContext.createGain();

                                    // 应用淡入淡出效果避免爆音
                                    const fadeDuration = 0.02; // 20毫秒
                                    gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                                    gainNode.gain.linearRampToValueAtTime(1, audioContext.currentTime + fadeDuration);

                                    const duration = audioBuffer.duration;
                                    if (duration > fadeDuration * 2) {
                                        gainNode.gain.setValueAtTime(1, audioContext.currentTime + duration - fadeDuration);
                                        gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + duration);
                                    }

                                    // 连接节点并开始播放
                                    this.source.connect(gainNode);
                                    gainNode.connect(audioContext.destination);

                                    this.lastPlayTime = audioContext.currentTime;
                                    log(`开始播放 ${currentSamples.length} 个样本，约 ${(currentSamples.length / SAMPLE_RATE).toFixed(2)} 秒`, 'info');
                                    this.source.start();
                                }
                                await this.getQueue(minSamples)
                            }
                        }
                    };
                }

                streamingContext.decodeOpusFrames();
                streamingContext.startPlaying();

            } catch (error) {
                log(`播放已缓冲的音频出错: ${error.message}`, 'error');
                isAudioPlaying = false;
                streamingContext = null;
            }
        }

        // 将Int16音频数据转换为Float32音频数据
        function convertInt16ToFloat32(int16Data) {
            const float32Data = new Float32Array(int16Data.length);
            for (let i = 0; i < int16Data.length; i++) {
                // 将[-32768,32767]范围转换为[-1,1]
                float32Data[i] = int16Data[i] / (int16Data[i] < 0 ? 0x8000 : 0x7FFF);
            }
            return float32Data;
        }

        // 初始化Opus解码器 - 确保完全初始化完成后才返回
        async function initOpusDecoder() {
            if (opusDecoder) return opusDecoder; // 已经初始化

            try {
                // 检查ModuleInstance是否存在
                if (typeof window.ModuleInstance === 'undefined') {
                    if (typeof Module !== 'undefined') {
                        // 使用全局Module作为ModuleInstance
                        window.ModuleInstance = Module;
                        log('使用全局Module作为ModuleInstance', 'info');
                    } else {
                        throw new Error('Opus库未加载，ModuleInstance和Module对象都不存在');
                    }
                }

                const mod = window.ModuleInstance;

                // 创建解码器对象
                opusDecoder = {
                    channels: CHANNELS,
                    rate: SAMPLE_RATE,
                    frameSize: FRAME_SIZE,
                    module: mod,
                    decoderPtr: null, // 初始为null

                    // 初始化解码器
                    init: function () {
                        if (this.decoderPtr) return true; // 已经初始化

                        // 获取解码器大小
                        const decoderSize = mod._opus_decoder_get_size(this.channels);
                        log(`Opus解码器大小: ${decoderSize}字节`, 'debug');

                        // 分配内存
                        this.decoderPtr = mod._malloc(decoderSize);
                        if (!this.decoderPtr) {
                            throw new Error("无法分配解码器内存");
                        }

                        // 初始化解码器
                        const err = mod._opus_decoder_init(
                            this.decoderPtr,
                            this.rate,
                            this.channels
                        );

                        if (err < 0) {
                            this.destroy(); // 清理资源
                            throw new Error(`Opus解码器初始化失败: ${err}`);
                        }

                        log("Opus解码器初始化成功", 'success');
                        return true;
                    },

                    // 解码方法
                    decode: function (opusData) {
                        if (!this.decoderPtr) {
                            if (!this.init()) {
                                throw new Error("解码器未初始化且无法初始化");
                            }
                        }

                        try {
                            const mod = this.module;

                            // 为Opus数据分配内存
                            const opusPtr = mod._malloc(opusData.length);
                            mod.HEAPU8.set(opusData, opusPtr);

                            // 为PCM输出分配内存
                            const pcmPtr = mod._malloc(this.frameSize * 2); // Int16 = 2字节

                            // 解码
                            const decodedSamples = mod._opus_decode(
                                this.decoderPtr,
                                opusPtr,
                                opusData.length,
                                pcmPtr,
                                this.frameSize,
                                0 // 不使用FEC
                            );

                            if (decodedSamples < 0) {
                                mod._free(opusPtr);
                                mod._free(pcmPtr);
                                throw new Error(`Opus解码失败: ${decodedSamples}`);
                            }

                            // 复制解码后的数据
                            const decodedData = new Int16Array(decodedSamples);
                            for (let i = 0; i < decodedSamples; i++) {
                                decodedData[i] = mod.HEAP16[(pcmPtr >> 1) + i];
                            }

                            // 释放内存
                            mod._free(opusPtr);
                            mod._free(pcmPtr);

                            return decodedData;
                        } catch (error) {
                            log(`Opus解码错误: ${error.message}`, 'error');
                            return new Int16Array(0);
                        }
                    },

                    // 销毁方法
                    destroy: function () {
                        if (this.decoderPtr) {
                            this.module._free(this.decoderPtr);
                            this.decoderPtr = null;
                        }
                    }
                };

                // 初始化解码器
                if (!opusDecoder.init()) {
                    throw new Error("Opus解码器初始化失败");
                }

                return opusDecoder;

            } catch (error) {
                log(`Opus解码器初始化失败: ${error.message}`, 'error');
                opusDecoder = null; // 重置为null，以便下次重试
                throw error;
            }
        }

        // 测试麦克风功能
        async function testMicrophone() {
            log('=== 开始麦克风测试 ===', 'info');
            
            const micTestButton = document.getElementById('micTestButton');
            if (!micTestButton) {
                log('找不到测试麦克风按钮', 'error');
                return;
            }
            
            micTestButton.disabled = true;
            micTestButton.textContent = '测试中...';
            
            try {
                // 首先检查安全环境
                const isSecureContext = location.protocol === 'https:' || 
                                      location.hostname === 'localhost' || 
                                      location.hostname === '127.0.0.1' ||
                                      location.hostname === '::1';
                
                if (!isSecureContext) {
                    log('🚨 麦克风测试失败：不安全的环境', 'error');
                    log('Chrome浏览器要求HTTPS环境或localhost才能使用麦克风', 'error');
                    log('当前访问地址：' + location.href, 'info');
                    log('', 'info');
                    log('解决方案：', 'info');
                    log('1. 使用HTTPS访问此页面', 'info');
                    log('2. 或者将服务器绑定到localhost并通过localhost访问', 'info');
                    throw new Error('不安全的环境，无法访问麦克风');
                }
                
                // 先进行兼容性检查
                log('检查浏览器兼容性...', 'info');
                
                // 检查权限状态
                if (navigator.permissions) {
                    try {
                        const permission = await navigator.permissions.query({name: 'microphone'});
                        log(`麦克风权限状态: ${permission.state}`, 'info');
                        if (permission.state === 'denied') {
                            log('麦克风权限被拒绝，请在浏览器设置中允许麦克风访问', 'error');
                            throw new Error('麦克风权限被拒绝');
                        } else if (permission.state === 'prompt') {
                            log('即将请求麦克风权限...', 'info');
                        } else if (permission.state === 'granted') {
                            log('麦克风权限已授予', 'success');
                        }
                    } catch (permError) {
                        if (permError.message === '麦克风权限被拒绝') {
                            throw permError;
                        }
                        log('无法查询权限状态: ' + permError.message, 'warning');
                    }
                }
                
                // 列出所有音频设备
                log('正在列出所有音频设备...', 'info');
                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const audioInputs = devices.filter(device => device.kind === 'audioinput');
                    const audioOutputs = devices.filter(device => device.kind === 'audiooutput');
                    
                    log(`发现音频输入设备 ${audioInputs.length} 个:`, 'info');
                    audioInputs.forEach((device, index) => {
                        log(`  ${index + 1}. ${device.label || '未知设备'} (ID: ${device.deviceId.substring(0, 12)}...)`, 'info');
                    });
                    
                    log(`发现音频输出设备 ${audioOutputs.length} 个:`, 'info');
                    audioOutputs.forEach((device, index) => {
                        log(`  ${index + 1}. ${device.label || '未知设备'} (ID: ${device.deviceId.substring(0, 12)}...)`, 'info');
                    });
                    
                    if (audioInputs.length === 0) {
                        throw new Error('未发现任何音频输入设备，请检查耳机/麦克风连接');
                    }
                } catch (deviceError) {
                    log(`设备枚举失败: ${deviceError.message}`, 'error');
                    throw deviceError;
                }
                
                log('正在请求麦克风权限...', 'info');
                log('📢 浏览器将弹出权限请求对话框，请点击"允许"以继续测试', 'info');
                
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,
                        channelCount: 1
                    }
                });
                
                log('✓ 麦克风权限获取成功', 'success');
                
                // 获取音频轨道信息
                const audioTracks = stream.getAudioTracks();
                if (audioTracks.length > 0) {
                    const track = audioTracks[0];
                    const settings = track.getSettings();
                    const capabilities = track.getCapabilities();
                    
                    log(`✓ 音频轨道信息:`, 'success');
                    log(`  - 状态: ${track.readyState}`, 'info');
                    log(`  - 标签: ${track.label}`, 'info');
                    log(`  - 采样率: ${settings.sampleRate}Hz`, 'info');
                    log(`  - 声道数: ${settings.channelCount}`, 'info');
                    log(`  - 回声消除: ${settings.echoCancellation}`, 'info');
                    log(`  - 噪声抑制: ${settings.noiseSuppression}`, 'info');
                    
                    if (capabilities) {
                        log(`  - 支持的采样率范围: ${capabilities.sampleRate?.min || '未知'}-${capabilities.sampleRate?.max || '未知'}Hz`, 'info');
                        log(`  - 支持的声道数: ${capabilities.channelCount?.min || '未知'}-${capabilities.channelCount?.max || '未知'}`, 'info');
                    }
                }
                
                // 测试MediaRecorder
                log('正在测试MediaRecorder...', 'info');
                try {
                    const recorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    log(`✓ MediaRecorder创建成功，MIME类型: ${recorder.mimeType}`, 'success');
                } catch (e) {
                    log(`⚠ MediaRecorder (Opus) 创建失败: ${e.message}`, 'warning');
                    try {
                        const recorder = new MediaRecorder(stream);
                        log(`✓ MediaRecorder (默认) 创建成功，MIME类型: ${recorder.mimeType}`, 'success');
                    } catch (e2) {
                        log(`✗ MediaRecorder 创建失败: ${e2.message}`, 'error');
                    }
                }
                
                // 测试音频上下文
                log('正在测试AudioContext...', 'info');
                try {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });
                    
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    source.connect(analyser);
                    
                    log(`✓ AudioContext创建成功，采样率: ${audioContext.sampleRate}Hz，状态: ${audioContext.state}`, 'success');
                    
                    // 简单的音频电平测试
                    const dataArray = new Uint8Array(analyser.frequencyBinCount);
                    let maxLevel = 0;
                    let samples = 0;
                    
                    log('正在进行5秒音频电平测试，请对着麦克风说话...', 'info');
                    
                    const levelTest = setInterval(() => {
                        analyser.getByteFrequencyData(dataArray);
                        const level = Math.max(...dataArray);
                        maxLevel = Math.max(maxLevel, level);
                        samples++;
                        
                        if (samples % 10 === 0) { // 每秒更新一次
                            log(`  当前音频电平: ${level}/255, 最大电平: ${maxLevel}/255`, 'info');
                        }
                    }, 100);
                    
                    setTimeout(() => {
                        clearInterval(levelTest);
                        audioContext.close();
                        
                        if (maxLevel > 10) {
                            log(`✓ 音频电平测试通过，最大电平: ${maxLevel}/255`, 'success');
                        } else {
                            log(`⚠ 音频电平测试警告，最大电平: ${maxLevel}/255，可能麦克风音量过低或未检测到声音`, 'warning');
                        }
                        
                        log('=== 麦克风测试完成 ===', 'success');
                    }, 5000);
                    
                } catch (e) {
                    log(`✗ AudioContext创建失败: ${e.message}`, 'error');
                }
                
                // 关闭流
                setTimeout(() => {
                    stream.getTracks().forEach(track => track.stop());
                    log('已释放麦克风资源', 'info');
                }, 6000);
                
            } catch (error) {
                log(`✗ 麦克风测试失败: ${error.message}`, 'error');
                
                if (error.name === 'NotAllowedError') {
                    log('🚫 您拒绝了麦克风权限，或浏览器阻止了麦克风访问', 'error');
                    log('💡 解决方法：', 'info');
                    log('   1. 点击浏览器地址栏左侧的小锁图标', 'info');
                    log('   2. 将麦克风权限设置为"允许"', 'info');
                    log('   3. 刷新页面并重新测试', 'info');
                } else if (error.name === 'NotFoundError') {
                    log('🎤 未找到麦克风设备', 'error');
                    log('💡 请检查：', 'info');
                    log('   1. 麦克风设备是否正确连接', 'info');
                    log('   2. 系统音频设置中是否启用了麦克风', 'info');
                    log('   3. 其他应用是否能正常使用麦克风', 'info');
                } else if (error.name === 'NotReadableError') {
                    log('🔒 麦克风被其他应用占用或硬件错误', 'error');
                    log('💡 请尝试：', 'info');
                    log('   1. 关闭其他使用麦克风的程序（如视频会议软件）', 'info');
                    log('   2. 重新插拔麦克风设备', 'info');
                    log('   3. 重启浏览器后再试', 'info');
                } else if (error.message === '麦克风权限被拒绝') {
                    log('🚫 麦克风权限已被永久拒绝', 'error');
                    log('💡 解决方法：', 'info');
                    log('   1. 点击地址栏左侧的权限图标', 'info');
                    log('   2. 重置麦克风权限或设置为允许', 'info');
                    log('   3. 刷新页面重试', 'info');
                } else {
                    log('💡 请检查浏览器是否支持麦克风功能，或尝试使用Chrome/Edge浏览器', 'info');
                }
            } finally {
                // 确保按钮状态总是能恢复
                setTimeout(() => {
                    const micTestButton = document.getElementById('micTestButton');
                    if (micTestButton) {
                        micTestButton.disabled = false;
                        micTestButton.textContent = '测试麦克风';
                    }
                }, 1000); // 减少等待时间到1秒
            }
        }

        // 检查浏览器兼容性
        function checkBrowserCompatibility() {
            log('=== 浏览器兼容性检查 ===', 'info');
            
            // 检查基本API支持
            const features = {
                'WebSocket': typeof WebSocket !== 'undefined',
                'getUserMedia': navigator.mediaDevices && typeof navigator.mediaDevices.getUserMedia === 'function',
                'MediaRecorder': typeof MediaRecorder !== 'undefined',
                'AudioContext': typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined',
                'WebAssembly': typeof WebAssembly !== 'undefined'
            };
            
            let allSupported = true;
            for (const [feature, supported] of Object.entries(features)) {
                if (supported) {
                    log(`✓ ${feature}: 支持`, 'success');
                } else {
                    log(`✗ ${feature}: 不支持`, 'error');
                    allSupported = false;
                }
            }
            
            // 检查MediaRecorder编码支持
            if (typeof MediaRecorder !== 'undefined') {
                const codecs = [
                    'audio/webm;codecs=opus',
                    'audio/webm',
                    'audio/ogg;codecs=opus',
                    'audio/mp4',
                    'audio/mpeg'
                ];
                
                log('MediaRecorder编码支持:', 'info');
                for (const codec of codecs) {
                    if (MediaRecorder.isTypeSupported(codec)) {
                        log(`✓ ${codec}: 支持`, 'success');
                    } else {
                        log(`✗ ${codec}: 不支持`, 'warning');
                    }
                }
            }
            
            // 浏览器信息
            log(`浏览器: ${navigator.userAgent}`, 'info');
            log(`协议: ${location.protocol}`, 'info');
            log(`主机名: ${location.hostname}`, 'info');
            
            // 检查HTTPS环境
            const isSecureContext = location.protocol === 'https:' || 
                                  location.hostname === 'localhost' || 
                                  location.hostname === '127.0.0.1' ||
                                  location.hostname === '::1';
            
            if (!isSecureContext) {
                log('🚨 重要警告：当前环境不支持麦克风和摄像头', 'error');
                log('Chrome/Edge浏览器要求HTTPS环境才能使用麦克风和摄像头', 'error');
                log('', 'info');
                log('📋 解决方案：', 'info');
                log('方案1: 使用HTTPS访问', 'info');
                log('   • 配置SSL证书，使用https://访问', 'info');
                log('方案2: 使用localhost访问', 'info');
                log('   • 将服务绑定到localhost，使用localhost:端口访问', 'info');
                log('方案3: 临时允许HTTP（不推荐）', 'info');
                log('   • Chrome地址栏输入：chrome://flags/#unsafely-treat-insecure-origin-as-secure', 'info');
                log('   • 添加当前域名到允许列表', 'info');
                log('', 'info');
            } else {
                log('✅ 安全环境检查通过，支持麦克风和摄像头访问', 'success');
            }
            
            // 添加麦克风使用提示
            log('🎤 麦克风测试说明：', 'info');
            if (isSecureContext) {
                log('   • 点击"测试麦克风"按钮开始测试', 'info');
                log('   • 首次使用时浏览器会请求麦克风权限，请点击"允许"', 'info');
                log('   • 如果权限被拒绝，请点击地址栏左侧的权限图标重新设置', 'info');
            } else {
                log('   • ⚠️ 当前环境无法使用麦克风功能', 'warning');
                log('   • 请按上述解决方案切换到安全环境', 'warning');
            };
            
            return allSupported;
        }

        // 初始化音频录制和处理
        async function initAudio() {
            try {
                log('开始初始化音频系统...', 'info');
                
                // 检查浏览器是否支持必要的API
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error('浏览器不支持麦克风访问API (navigator.mediaDevices.getUserMedia)');
                }
                
                log('浏览器支持检查通过，正在请求麦克风权限...', 'info');
                
                // 首先列出可用的音频输入设备
                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const audioInputs = devices.filter(device => device.kind === 'audioinput');
                    log(`发现 ${audioInputs.length} 个音频输入设备:`, 'info');
                    audioInputs.forEach((device, index) => {
                        log(`  ${index + 1}. ${device.label || '未知设备'} (${device.deviceId.substring(0, 8)}...)`, 'info');
                    });
                    
                    if (audioInputs.length === 0) {
                        throw new Error('未发现任何音频输入设备');
                    }
                } catch (deviceError) {
                    log(`设备枚举失败: ${deviceError.message}，继续尝试默认设备`, 'warning');
                }
                
                // 请求麦克风权限
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,  // 确保16kHz采样率
                        channelCount: 1     // 确保单声道
                    }
                });
                log('已获取麦克风访问权限', 'success');

                // 创建音频上下文
                audioContext = getAudioContextInstance();
                const source = audioContext.createMediaStreamSource(stream);
                log('媒体流源创建成功', 'success');

                // 获取实际音频轨道设置
                const audioTracks = stream.getAudioTracks();
                if (audioTracks.length > 0) {
                    const track = audioTracks[0];
                    const settings = track.getSettings();
                    log(`实际麦克风设置 - 采样率: ${settings.sampleRate || '未知'}Hz, 声道数: ${settings.channelCount || '未知'}`, 'info');
                    
                    // 检查麦克风状态
                    if (track.readyState !== 'live') {
                        log(`警告：麦克风状态异常: ${track.readyState}`, 'warning');
                    }
                } else {
                    throw new Error('无法获取音频轨道信息');
                }

                // 创建分析器用于可视化
                log('正在创建音频分析器...', 'info');
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                source.connect(analyser);
                log('音频分析器创建成功', 'success');

                // 尝试初始化MediaRecorder，按优先级尝试不同编码选项
                log('正在初始化MediaRecorder...', 'info');
                try {
                    // 检查是否支持Opus编码
                    if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                        mediaRecorder = new MediaRecorder(stream, {
                            mimeType: 'audio/webm;codecs=opus',
                            audioBitsPerSecond: 16000
                        });
                        log('已初始化MediaRecorder (使用Opus编码)', 'success');
                        log(`选择的编码格式: ${mediaRecorder.mimeType}`, 'info');
                    } else {
                        log('浏览器不支持Opus编码，尝试其他格式...', 'warning');
                        throw new Error('Opus不支持');
                    }
                } catch (e1) {
                    log(`Opus编码失败: ${e1.message}`, 'warning');
                    try {
                        // 如果Opus不支持，尝试WebM
                        if (MediaRecorder.isTypeSupported('audio/webm')) {
                            mediaRecorder = new MediaRecorder(stream, {
                                mimeType: 'audio/webm',
                                audioBitsPerSecond: 16000
                            });
                            log('已初始化MediaRecorder (使用WebM编码)', 'warning');
                            log(`选择的编码格式: ${mediaRecorder.mimeType}`, 'info');
                        } else {
                            throw new Error('WebM不支持');
                        }
                    } catch (e2) {
                        log(`WebM编码失败: ${e2.message}`, 'warning');
                        try {
                            // 最后尝试默认格式
                            mediaRecorder = new MediaRecorder(stream);
                            log('已初始化MediaRecorder (使用默认编码)', 'warning');
                            log(`选择的编码格式: ${mediaRecorder.mimeType}`, 'info');
                        } catch (e3) {
                            throw new Error(`所有MediaRecorder编码格式都不支持: ${e3.message}`);
                        }
                    }
                }

                log('MediaRecorder初始化成功', 'success');

                // 处理录制的数据
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                // 录制结束后处理数据
                mediaRecorder.onstop = async () => {
                    // 停止可视化
                    if (visualizationRequest) {
                        cancelAnimationFrame(visualizationRequest);
                        visualizationRequest = null;
                    }

                    log(`录音结束，已收集的音频块数量: ${audioChunks.length}`, 'info');
                    if (audioChunks.length === 0) {
                        log('警告：没有收集到任何音频数据，请检查麦克风是否工作正常', 'error');
                        return;
                    }

                    // 创建完整的录音blob
                    const blob = new Blob(audioChunks, { type: audioChunks[0].type });
                    log(`已创建音频Blob，MIME类型: ${audioChunks[0].type}，大小: ${(blob.size / 1024).toFixed(2)} KB`, 'info');

                    // 保存原始块，以防清空后需要调试
                    const chunks = [...audioChunks];
                    audioChunks = [];

                    try {
                        // 将blob转换为ArrayBuffer
                        const arrayBuffer = await blob.arrayBuffer();
                        const uint8Array = new Uint8Array(arrayBuffer);

                        log(`已转换为Uint8Array，准备发送，大小: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`, 'info');

                        // 检查WebSocket状态
                        if (!websocket) {
                            log('错误：WebSocket连接不存在', 'error');
                            return;
                        }

                        if (websocket.readyState !== WebSocket.OPEN) {
                            log(`错误：WebSocket连接未打开，当前状态: ${websocket.readyState}`, 'error');
                            return;
                        }

                        // 直接发送二进制音频数据 - 这是最简单有效的方式
                        try {
                            // 注意：开始和结束消息已在录音开始和结束时发送
                            // 这里只需要发送音频数据
                            await new Promise(resolve => setTimeout(resolve, 50));

                            // 处理WebM容器格式，提取纯Opus数据
                            // 服务器使用opuslib_next.Decoder，需要纯Opus帧
                            log('正在处理音频数据，提取纯Opus帧...', 'info');
                            const opusData = extractOpusFrames(uint8Array);

                            // 记录Opus数据大小
                            log(`已提取Opus数据，大小: ${(opusData.byteLength / 1024).toFixed(2)} KB`, 'info');

                            // 发送音频消息第二步：二进制音频数据
                            websocket.send(opusData);
                            log(`已发送Opus音频数据: ${(opusData.byteLength / 1024).toFixed(2)} KB`, 'success');
                        } catch (error) {
                            log(`音频数据发送失败: ${error.message}`, 'error');

                            // 尝试使用base64编码作为备选方案
                            try {
                                log('尝试使用base64编码方式发送...', 'info');
                                const base64Data = arrayBufferToBase64(arrayBuffer);
                                const audioDataMessage = {
                                    type: 'audio',
                                    action: 'data',
                                    format: 'opus',
                                    sample_rate: 16000,
                                    channels: 1,
                                    mime_type: chunks[0].type,
                                    encoding: 'base64',
                                    data: base64Data
                                };
                                websocket.send(JSON.stringify(audioDataMessage));
                                log(`已使用base64编码发送音频数据: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`, 'warning');
                            } catch (base64Error) {
                                log(`所有数据发送方式均失败: ${base64Error.message}`, 'error');
                            }
                        }
                    } catch (error) {
                        log(`处理录音数据错误: ${error.message}`, 'error');
                    }
                };

                // 尝试初始化Opus解码器
                try {
                    // 检查ModuleInstance是否存在（本地库导出的全局变量）
                    if (typeof window.ModuleInstance === 'undefined') {
                        throw new Error('Opus库未加载，ModuleInstance对象不存在');
                    }

                    // 简单测试ModuleInstance是否可用
                    if (typeof window.ModuleInstance._opus_decoder_get_size === 'function') {
                        const testSize = window.ModuleInstance._opus_decoder_get_size(1);
                        log(`Opus解码器测试成功，解码器大小: ${testSize} 字节`, 'success');
                    } else {
                        throw new Error('Opus解码函数未找到');
                    }
                } catch (err) {
                    log(`Opus解码器初始化警告: ${err.message}，将在需要时重试`, 'warning');
                }

                log('音频系统初始化完成', 'success');
                return true;
            } catch (error) {
                log(`音频初始化错误: ${error.message}`, 'error');
                
                // 提供具体的错误分析和解决建议
                if (error.name === 'NotAllowedError' || error.message.includes('Permission denied')) {
                    log('错误原因：麦克风权限被拒绝', 'error');
                    log('解决方案：', 'info');
                    log('1. 点击浏览器地址栏左侧的🔒或🔊图标，允许麦克风权限', 'info');
                    log('2. 在Chrome中：设置 → 隐私和安全 → 网站设置 → 麦克风 → 允许', 'info');
                    log('3. 确保系统设置中允许浏览器访问麦克风', 'info');
                    log('4. 刷新页面重试', 'info');
                } else if (error.name === 'NotFoundError') {
                    log('错误原因：未找到麦克风设备', 'error');
                    log('解决方案：', 'info');
                    log('1. 确保耳机已正确连接到电脑', 'info');
                    log('2. 检查耳机是否有麦克风功能', 'info');
                    log('3. 在系统声音设置中检查麦克风是否被识别', 'info');
                    log('4. 尝试重新插拔耳机', 'info');
                    log('5. 重启浏览器重试', 'info');
                } else if (error.name === 'NotReadableError') {
                    log('错误原因：麦克风设备正在被其他应用使用', 'error');
                    log('解决方案：', 'info');
                    log('1. 关闭其他正在使用麦克风的应用（如Zoom、Teams等）', 'info');
                    log('2. 关闭其他浏览器标签页', 'info');
                    log('3. 重启浏览器重试', 'info');
                } else if (error.name === 'OverconstrainedError') {
                    log('错误原因：麦克风不支持请求的音频参数', 'error');
                    log('解决方案：', 'info');
                    log('1. 您的麦克风可能不支持16kHz采样率', 'info');
                    log('2. 尝试使用更新版本的浏览器', 'info');
                    log('3. 检查耳机规格是否支持高质量音频录制', 'info');
                } else if (error.message.includes('AudioContext')) {
                    log('错误原因：音频上下文创建失败', 'error');
                    log('解决方案：', 'info');
                    log('1. 确保浏览器支持Web Audio API', 'info');
                    log('2. 尝试用户手动点击页面激活音频上下文', 'info');
                    log('3. 检查是否有其他音频应用冲突', 'info');
                } else if (error.message.includes('MediaRecorder')) {
                    log('错误原因：MediaRecorder初始化失败', 'error');
                    log('解决方案：', 'info');
                    log('1. 确保浏览器支持MediaRecorder API', 'info');
                    log('2. 尝试使用Chrome或Firefox浏览器', 'info');
                    log('3. 更新浏览器到最新版本', 'info');
                } else if (error.message.includes('设备')) {
                    log('错误原因：音频设备相关问题', 'error');
                    log('解决方案：', 'info');
                    log('1. 检查耳机是否正确连接', 'info');
                    log('2. 在系统设置中检查默认音频设备', 'info');
                    log('3. 尝试重新插拔耳机', 'info');
                    log('4. 重启电脑后重试', 'info');
                } else {
                    log('其他音频初始化错误，错误详情如上', 'warning');
                    log('通用解决方案：', 'info');
                    log('1. 确保使用HTTPS或localhost访问页面', 'info');
                    log('2. 尝试使用Chrome或Firefox浏览器', 'info');
                    log('3. 刷新页面重试', 'info');
                    log('4. 检查浏览器控制台是否有其他错误信息', 'info');
                    log('5. 尝试点击"测试麦克风"按钮单独测试', 'info');
                }
                
                return false;
            }
        }

        // 开始录音
        function startRecording() {
            if (isRecording) return;

            try {
                // 最小录音时长提示
                log('请至少录制1-2秒钟的音频，确保采集到足够数据', 'info');

                // 获取服务器类型 - 从URL判断
                const serverUrl = serverUrlInput.value.trim();
                let isXiaozhiNative = false;

                // 检查是否是小智原生服务器 (根据URL特征判断)
                if (serverUrl.includes('xiaozhi') || serverUrl.includes('localhost') || serverUrl.includes('127.0.0.1')) {
                    isXiaozhiNative = true;
                    log('检测到小智原生服务器，使用标准listen协议', 'info');
                }

                // 使用直接PCM录音和libopus编码的方式
                startDirectRecording();
            } catch (error) {
                log(`录音启动错误: ${error.message}`, 'error');
            }
        }

        // 停止录音
        function stopRecording() {
            if (!isRecording) return;

            try {
                // 使用直接PCM录音停止
                stopDirectRecording();
            } catch (error) {
                log(`停止录音错误: ${error.message}`, 'error');
            }
        }

        // 连接WebSocket服务器
        async function connectToServer() {
            const url = serverUrlInput.value.trim();
            const config = getConfig();
            // 先检查OTA状态
            log('正在检查OTA状态...', 'info');
            const otaUrl = document.getElementById('otaUrl').value.trim();
            localStorage.setItem('otaUrl', otaUrl);
            localStorage.setItem('wsUrl', url);

            try {
                const ws = await webSocketConnect(otaUrl, url, config)
                if (ws === undefined) {
                    return
                }
                websocket = ws

                // 设置接收二进制数据的类型为ArrayBuffer
                websocket.binaryType = 'arraybuffer';

                // 设置连接超时
                const connectionTimeout = setTimeout(() => {
                    if (websocket && websocket.readyState === WebSocket.CONNECTING) {
                        log('WebSocket连接超时 (10秒)，正在关闭连接...', 'error');
                        websocket.close();
                        connectionStatus.textContent = 'ws连接超时';
                        connectionStatus.style.color = 'red';
                    }
                }, 10000); // 10秒超时

                websocket.onopen = async () => {
                    clearTimeout(connectionTimeout); // 清除超时定时器
                    connectionRetryCount = 0; // 重置重试计数器
                    log(`WebSocket连接成功建立!`, 'success');
                    log(`连接详情: ${JSON.stringify({
                        readyState: websocket.readyState,
                        url: websocket.url,
                        protocol: websocket.protocol,
                        extensions: websocket.extensions
                    })}`, 'debug');
                    
                    connectionStatus.textContent = 'ws已连接';
                    connectionStatus.style.color = 'green';

                    // 连接成功后发送hello消息
                    await sendHelloMessage();

                    connectButton.textContent = '断开';
                    connectButton.removeEventListener('click', connectToServer);
                    connectButton.addEventListener('click', disconnectFromServer);
                    // connectButton.onclick = disconnectFromServer;
                    messageInput.disabled = false;
                    sendTextButton.disabled = false;

                    const audioInitialized = await initAudio();
                    if (audioInitialized) {
                        recordButton.disabled = false;
                    }
                };

                websocket.onclose = (event) => {
                    clearTimeout(connectionTimeout); // 清除超时定时器
                    log('WebSocket连接已关闭', 'warning');
                    log(`关闭事件详情: ${JSON.stringify({
                        code: event.code,
                        reason: event.reason,
                        wasClean: event.wasClean,
                        type: event.type
                    })}`, 'debug');
                    
                    // 解析关闭代码
                    let closeReason = '未知原因';
                    switch(event.code) {
                        case 1000: closeReason = '正常关闭'; break;
                        case 1001: closeReason = '端点离开'; break;
                        case 1002: closeReason = '协议错误'; break;
                        case 1003: closeReason = '不支持的数据类型'; break;
                        case 1004: closeReason = '保留代码'; break;
                        case 1005: closeReason = '未提供状态码'; break;
                        case 1006: closeReason = '连接异常关闭(可能是网络问题或服务器拒绝连接)'; break;
                        case 1007: closeReason = '数据格式错误'; break;
                        case 1008: closeReason = '策略违规'; break;
                        case 1009: closeReason = '消息过大'; break;
                        case 1010: closeReason = '扩展协商失败'; break;
                        case 1011: closeReason = '服务器错误'; break;
                        case 1012: closeReason = '服务重启'; break;
                        case 1013: closeReason = '稍后重试'; break;
                        case 1014: closeReason = '网关超时'; break;
                        case 1015: closeReason = 'TLS握手失败'; break;
                        default: closeReason = `自定义代码: ${event.code}`;
                    }
                    
                    log(`关闭原因: ${closeReason} (代码: ${event.code})`, 'warning');
                    if (event.reason) {
                        log(`服务器消息: ${event.reason}`, 'warning');
                    }

                    // 检查是否是由于HEAD请求导致的立即关闭
                    if (event.code === 1006 && !event.wasClean) {
                        log('检测到异常关闭，可能是服务器拒绝了非GET请求', 'error');
                        log('服务器日志可能显示: "unsupported HTTP method; expected GET; got HEAD"', 'error');
                        log('建议尝试：', 'info');
                        log('1. 刷新页面重试', 'info');
                        log('2. 使用不同的浏览器', 'info');
                        log('3. 检查是否有网络代理干扰', 'info');
                        
                        // 尝试自动重试
                        if (connectionRetryCount < maxRetryAttempts) {
                            connectionRetryCount++;
                            log(`准备进行第${connectionRetryCount}次重试连接...`, 'info');
                            setTimeout(() => {
                                log(`开始第${connectionRetryCount}次重试`, 'info');
                                connectToServer();
                            }, 2000 * connectionRetryCount); // 递增延迟重试
                            return;
                        } else {
                            log(`已达到最大重试次数(${maxRetryAttempts})，停止重试`, 'error');
                            connectionRetryCount = 0; // 重置重试计数
                        }
                    }

                    connectionStatus.textContent = 'ws已断开';
                    connectionStatus.style.color = 'red';

                    connectButton.textContent = '连接';
                    connectButton.removeEventListener('click', disconnectFromServer);
                    connectButton.addEventListener('click', connectToServer);
                    // connectButton.onclick = connectToServer;
                    messageInput.disabled = true;
                    sendTextButton.disabled = true;
                    recordButton.disabled = true;
                    stopButton.disabled = true;
                };

                websocket.onerror = (error) => {
                    clearTimeout(connectionTimeout); // 清除超时定时器
                    log(`WebSocket错误发生`, 'error');
                    log(`错误事件详情: ${JSON.stringify({
                        type: error.type,
                        target: error.target ? {
                            readyState: error.target.readyState,
                            url: error.target.url,
                            protocol: error.target.protocol
                        } : null,
                        timeStamp: error.timeStamp,
                        message: error.message || '无错误消息'
                    })}`, 'debug');
                    
                    // 尝试获取更多错误信息
                    if (error.target) {
                        const readyStateNames = ['CONNECTING', 'OPEN', 'CLOSING', 'CLOSED'];
                        log(`连接状态: ${error.target.readyState} (${readyStateNames[error.target.readyState] || 'UNKNOWN'})`, 'debug');
                        if (error.target.url) {
                            log(`尝试连接的URL: ${error.target.url}`, 'debug');
                        }
                    }
                    
                    // 检查是否是HEAD请求问题
                    if (error.target && error.target.readyState === WebSocket.CLOSED) {
                        log('检测到连接立即关闭，可能是服务器拒绝了非GET请求', 'warning');
                        log('建议检查服务器日志中是否有"unsupported HTTP method"错误', 'warning');
                        log('这通常是由于网络代理或浏览器发送了HEAD请求而不是GET请求', 'warning');
                    }
                    
                    connectionStatus.textContent = 'ws连接错误';
                    connectionStatus.style.color = 'red';
                };

                websocket.onmessage = function (event) {
                    try {
                        // 检查是否为文本消息
                        if (typeof event.data === 'string') {
                            const message = JSON.parse(event.data);

                            if (message.type === 'hello') {
                                log(`服务器回应：${JSON.stringify(message, null, 2)}`, 'success');
                            } else if (message.type === 'tts') {
                                // TTS状态消息
                                if (message.state === 'start') {
                                    log('服务器开始发送语音', 'info');
                                } else if (message.state === 'sentence_start') {
                                    log(`服务器发送语音段: ${message.text}`, 'info');
                                    // 添加文本到会话记录
                                    if (message.text) {
                                        addMessage(message.text);
                                    }
                                } else if (message.state === 'sentence_end') {
                                    log(`语音段结束: ${message.text}`, 'info');
                                } else if (message.state === 'stop') {
                                    log('服务器语音传输结束', 'info');
                                    // 结束后更新UI状态
                                    if (recordButton.disabled) {
                                        recordButton.disabled = false;
                                        recordButton.textContent = '开始录音';
                                        recordButton.classList.remove('recording');
                                    }
                                }
                            } else if (message.type === 'audio') {
                                // 音频控制消息
                                log(`收到音频控制消息: ${JSON.stringify(message)}`, 'info');
                            } else if (message.type === 'stt') {
                                // 语音识别结果
                                log(`识别结果: ${message.text}`, 'info');
                                // 添加识别结果到会话记录
                                addMessage(`[语音识别] ${message.text}`, true);
                            } else if (message.type === 'llm') {
                                // 大模型回复
                                log(`大模型回复: ${message.text}`, 'info');
                                // 添加大模型回复到会话记录
                                if (message.text && message.text !== '😊') {
                                    addMessage(message.text);
                                }
                            } else if (message.type === 'mcp') {
                                const payload = message.payload || {};
                                log(`服务器下发: ${JSON.stringify(message)}`, 'info');
                                if (payload) {
                                    // 模拟小智客户端行为
                                    if (payload.method === 'tools/list') {
                                        const replay_message = JSON.stringify({
                                            "session_id": "", "type": "mcp", "payload": {
                                                "jsonrpc": "2.0", "id": 2, "result": {
                                                    "tools": [{
                                                        "name": "self.get_device_status",
                                                        "description": "Provides the real-time information of the device, including the current status of the audio speaker, screen, battery, network, etc.\nUse this tool for: \n1. Answering questions about current condition (e.g. what is the current volume of the audio speaker?)\n2. As the first step to control the device (e.g. turn up / down the volume of the audio speaker, etc.)",
                                                        "inputSchema": { "type": "object", "properties": {} }
                                                    }, {
                                                        "name": "self.audio_speaker.set_volume",
                                                        "description": "Set the volume of the audio speaker. If the current volume is unknown, you must call `self.get_device_status` tool first and then call this tool.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": {
                                                                "volume": {
                                                                    "type": "integer",
                                                                    "minimum": 0,
                                                                    "maximum": 100
                                                                }
                                                            },
                                                            "required": ["volume"]
                                                        }
                                                    }, {
                                                        "name": "self.screen.set_brightness",
                                                        "description": "Set the brightness of the screen.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": {
                                                                "brightness": {
                                                                    "type": "integer",
                                                                    "minimum": 0,
                                                                    "maximum": 100
                                                                }
                                                            },
                                                            "required": ["brightness"]
                                                        }
                                                    }, {
                                                        "name": "self.screen.set_theme",
                                                        "description": "Set the theme of the screen. The theme can be 'light' or 'dark'.",
                                                        "inputSchema": {
                                                            "type": "object",
                                                            "properties": { "theme": { "type": "string" } },
                                                            "required": ["theme"]
                                                        }
                                                    }]
                                                }
                                            }
                                        })
                                        websocket.send(replay_message);
                                        log(`回复MCP消息: ${replay_message}`, 'info');
                                    } else if (payload.method === 'tools/call') {
                                        // 模拟回复
                                        const replay_message = JSON.stringify({
                                            "session_id": "9f261599",
                                            "type": "mcp",
                                            "payload": {
                                                "jsonrpc": "2.0",
                                                "id": payload.id,
                                                "result": { "content": [{ "type": "text", "text": "true" }], "isError": false }
                                            }
                                        })
                                        websocket.send(replay_message);
                                        log(`回复MCP消息: ${replay_message}`, 'info');
                                    }
                                }

                            } else {
                                // 未知消息类型
                                log(`未知消息类型: ${message.type}`, 'info');
                                addMessage(JSON.stringify(message, null, 2));
                            }
                        } else {
                            // 处理二进制数据 - 兼容多种二进制格式
                            handleBinaryMessage(event.data);
                        }
                    } catch (error) {
                        log(`WebSocket消息处理错误: ${error.message}`, 'error');
                        // 非JSON格式文本消息直接显示
                        if (typeof event.data === 'string') {
                            addMessage(event.data);
                        }
                    }
                };

                connectionStatus.textContent = 'ws未连接';
                connectionStatus.style.color = 'orange';
            } catch (error) {
                log(`连接过程中发生异常: ${error.name}: ${error.message}`, 'error');
                log(`错误堆栈: ${error.stack}`, 'debug');
                log(`错误类型: ${typeof error}`, 'debug');
                
                // 检查是否是网络相关错误
                if (error.name === 'NetworkError' || error.message.includes('network')) {
                    log('这是网络连接错误，请检查：', 'error');
                    log('1. 服务器IP地址是否正确', 'error');
                    log('2. 服务器端口是否开放', 'error');
                    log('3. 防火墙是否阻止了连接', 'error');
                    log('4. 网络是否正常', 'error');
                } else if (error.message.includes('ECONNREFUSED')) {
                    log('连接被拒绝，服务器可能未启动或端口不正确', 'error');
                } else if (error.message.includes('timeout')) {
                    log('连接超时，服务器响应缓慢或不可达', 'error');
                }
                
                // 针对HEAD请求问题的特殊处理
                log('=== 常见问题解决方案 ===', 'info');
                log('如果服务器日志显示"unsupported HTTP method; expected GET; got HEAD"：', 'info');
                log('1. 这是浏览器或网络代理发送了HEAD请求而不是GET请求', 'info');
                log('2. 解决方案：', 'info');
                log('   - 尝试刷新页面重新连接', 'info');
                log('   - 使用Chrome隐私模式或Firefox隐私窗口', 'info');
                log('   - 检查是否有企业代理或VPN干扰', 'info');
                log('   - 确保访问的是正确的服务器IP和端口', 'info');
                log('3. 当前尝试连接的地址：' + url, 'info');
                
                connectionStatus.textContent = 'ws连接失败';
                connectionStatus.style.color = 'red';
                
                // 重置按钮状态
                connectButton.textContent = '连接';
                connectButton.removeEventListener('click', disconnectFromServer);
                connectButton.addEventListener('click', connectToServer);
            }
        }

        // 发送hello握手消息
        async function sendHelloMessage() {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) return;

            try {
                const config = getConfig();

                // 设置设备信息
                const helloMessage = {
                    type: 'hello',
                    device_id: config.deviceId,
                    device_name: config.deviceName,
                    device_mac: config.deviceMac,
                    token: config.token,
                    features: {
                        mcp: true
                    }
                };

                log('发送hello握手消息', 'info');
                websocket.send(JSON.stringify(helloMessage));

                // 等待服务器响应
                return new Promise(resolve => {
                    // 5秒超时
                    const timeout = setTimeout(() => {
                        log('等待hello响应超时', 'error');
                        log('提示: 请尝试点击"测试认证"按钮进行连接排查', 'info');
                        resolve(false);
                    }, 5000);

                    // 临时监听一次消息，接收hello响应
                    const onMessageHandler = (event) => {
                        try {
                            const response = JSON.parse(event.data);
                            if (response.type === 'hello' && response.session_id) {
                                log(`服务器握手成功，会话ID: ${response.session_id}`, 'success');
                                clearTimeout(timeout);
                                websocket.removeEventListener('message', onMessageHandler);
                                resolve(true);
                            }
                        } catch (e) {
                            // 忽略非JSON消息
                        }
                    };

                    websocket.addEventListener('message', onMessageHandler);
                });
            } catch (error) {
                log(`发送hello消息错误: ${error.message}`, 'error');
                return false;
            }
        }

        // 断开WebSocket连接
        function disconnectFromServer() {
            if (!websocket) return;

            websocket.close();
            stopRecording();
        }

        // 发送文本消息
        function sendTextMessage() {
            const message = messageInput.value.trim();
            if (message === '' || !websocket || websocket.readyState !== WebSocket.OPEN) return;


            try {
                // 直接发送listen消息，不需要重复发送hello
                const listenMessage = {
                    type: 'listen',
                    mode: 'manual',
                    state: 'detect',
                    text: message
                };

                websocket.send(JSON.stringify(listenMessage));
                addMessage(message, true);
                log(`发送文本消息: ${message}`, 'info');

                messageInput.value = '';
            } catch (error) {
                log(`发送消息错误: ${error.message}`, 'error');
            }
        }

        // 生成随机MAC地址
        function generateRandomMac() {
            const hexDigits = '0123456789ABCDEF';
            let mac = '';
            for (let i = 0; i < 6; i++) {
                if (i > 0) mac += ':';
                for (let j = 0; j < 2; j++) {
                    mac += hexDigits.charAt(Math.floor(Math.random() * 16));
                }
            }
            return mac;
        }

        // 初始化事件监听器
        function initEventListeners() {
            connectButton.addEventListener('click', connectToServer);
            document.getElementById('authTestButton').addEventListener('click', testAuthentication);
            document.getElementById('micTestButton').addEventListener('click', testMicrophone);

            // 设备配置面板折叠/展开
            const toggleButton = document.getElementById('toggleConfig');
            const configPanel = document.getElementById('configPanel');
            const deviceMacInput = document.getElementById('deviceMac');
            const clientIdInput = document.getElementById('clientId');
            const displayMac = document.getElementById('displayMac');
            const displayClient = document.getElementById('displayClient');

            // 从localStorage加载MAC地址，如果没有则生成新的
            let savedMac = localStorage.getItem('deviceMac');
            if (!savedMac) {
                savedMac = generateRandomMac();
                localStorage.setItem('deviceMac', savedMac);
            }
            deviceMacInput.value = savedMac;
            displayMac.textContent = savedMac;

            // 更新显示的值
            function updateDisplayValues() {
                const newMac = deviceMacInput.value;
                displayMac.textContent = newMac;
                displayClient.textContent = clientIdInput.value;
                // 保存MAC地址到localStorage
                localStorage.setItem('deviceMac', newMac);
            }

            // 监听输入变化
            deviceMacInput.addEventListener('input', updateDisplayValues);
            clientIdInput.addEventListener('input', updateDisplayValues);

            // 初始更新显示值
            updateDisplayValues();

            const savedOtaUrl = localStorage.getItem('otaUrl');
            if (savedOtaUrl) {
                document.getElementById('otaUrl').value = savedOtaUrl;
            }

            const savedWsUrl = localStorage.getItem('wsUrl');
            if (savedWsUrl) {
                document.getElementById('serverUrl').value = savedWsUrl;
            }

            // 切换面板显示
            toggleButton.addEventListener('click', () => {
                const isExpanded = configPanel.classList.contains('expanded');
                configPanel.classList.toggle('expanded');
                toggleButton.textContent = isExpanded ? '编辑' : '收起';
            });

            // 标签页切换
            const tabs = document.querySelectorAll('.tab');
            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    // 移除所有标签页的active类
                    tabs.forEach(t => t.classList.remove('active'));
                    document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));

                    // 添加当前标签页的active类
                    tab.classList.add('active');
                    document.getElementById(`${tab.dataset.tab}Tab`).classList.add('active');
                });
            });

            sendTextButton.addEventListener('click', sendTextMessage);
            messageInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') sendTextMessage();
            });

            recordButton.addEventListener('click', () => {
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            });

            window.addEventListener('resize', initVisualizer);
        }

        // 测试认证
        async function testAuthentication() {
            log('开始测试认证...', 'info');

            const config = getConfig();

            // 显示服务器配置
            log('-------- 服务器认证配置检查 --------', 'info');
            log('请确认config.yaml中的auth配置：', 'info');
            log('1. server.auth.enabled 为 false 或服务器已正确配置认证', 'info');
            log('2. 如果启用了认证，请确认使用了正确的token', 'info');
            log(`3. 或者在allowed_devices中添加了测试设备MAC：${config.deviceMac}`, 'info');

            const serverUrl = serverUrlInput.value.trim();
            if (!serverUrl) {
                log('请输入服务器地址', 'error');
                return;
            }

            // 测试连接
            log('尝试不同认证参数的连接：', 'info');

            // 测试1: 无参数连接
            try {
                log('测试1: 尝试无参数连接...', 'info');
                const ws1 = new WebSocket(serverUrl);

                ws1.onopen = () => {
                    log('测试1成功: 无参数可连接，服务器可能没有启用认证', 'success');
                    ws1.close();
                };

                ws1.onerror = (error) => {
                    log('测试1失败: 无参数连接被拒绝，服务器可能启用了认证', 'error');
                };

                // 5秒后关闭测试连接
                setTimeout(() => {
                    if (ws1.readyState === WebSocket.CONNECTING || ws1.readyState === WebSocket.OPEN) {
                        ws1.close();
                    }
                }, 5000);
            } catch (error) {
                log(`测试1出错: ${error.message}`, 'error');
            }

            // 测试2: 带参数连接
            setTimeout(async () => {
                try {
                    log('测试2: 尝试带token参数连接...', 'info');

                    let url = new URL(serverUrl);
                    url.searchParams.append('token', config.token);
                    url.searchParams.append('device_id', config.deviceId);
                    url.searchParams.append('device_mac', config.deviceMac);

                    const ws2 = new WebSocket(url.toString());

                    ws2.onopen = () => {
                        log('测试2成功: 带token参数可连接', 'success');

                        // 尝试发送hello消息
                        const helloMsg = {
                            type: 'hello',
                            device_id: config.deviceId,
                            device_mac: config.deviceMac,
                            token: config.token
                        };

                        ws2.send(JSON.stringify(helloMsg));
                        log('已发送hello测试消息', 'info');

                        // 监听响应
                        ws2.onmessage = (event) => {
                            try {
                                const response = JSON.parse(event.data);
                                if (response.type === 'hello' && response.session_id) {
                                    log(`测试完全成功! 收到hello响应，会话ID: ${response.session_id}`, 'success');
                                    ws2.close();
                                }
                            } catch (e) {
                                log(`收到非JSON响应: ${event.data}`, 'info');
                            }
                        };

                        // 5秒后关闭
                        setTimeout(() => ws2.close(), 5000);
                    };

                    ws2.onerror = (error) => {
                        log('测试2失败: 带token参数连接被拒绝', 'error');
                        log('请检查token是否正确，或服务器是否接受URL参数认证', 'error');
                    };
                } catch (error) {
                    log(`测试2出错: ${error.message}`, 'error');
                }
            }, 6000);

            log('认证测试已启动，请查看测试结果...', 'info');
        }

        // 帮助函数：ArrayBuffer转Base64
        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }

        // Opus编码器
        let opusEncoder;

        // 初始化应用
        function initApp() {
            initVisualizer();
            initEventListeners();
            checkEnvironment(); // 检查环境并显示警告

            // 检查libopus.js是否正确加载
            checkOpusLoaded();

            // 初始化Opus编码器
            opusEncoder = initOpusEncoder();

            // 预加载Opus解码器
            log('预加载Opus解码器...', 'info');
            initOpusDecoder().then(() => {
                log('Opus解码器预加载成功', 'success');
            }).catch(error => {
                log(`Opus解码器预加载失败: ${error.message}，将在需要时重试`, 'warning');
            });
            playBufferedAudio()
            startAudioBuffering()

        }

        // PCM录音处理器代码 - 会被注入到AudioWorklet中
        const audioProcessorCode = `
            class AudioRecorderProcessor extends AudioWorkletProcessor {
                constructor() {
                    super();
                    this.buffers = [];
                    this.frameSize = 960; // 60ms @ 16kHz = 960 samples
                    this.buffer = new Int16Array(this.frameSize);
                    this.bufferIndex = 0;
                    this.isRecording = false;

                    // 监听来自主线程的消息
                    this.port.onmessage = (event) => {
                        if (event.data.command === 'start') {
                            this.isRecording = true;
                            this.port.postMessage({ type: 'status', status: 'started' });
                        } else if (event.data.command === 'stop') {
                            this.isRecording = false;

                            // 发送剩余的缓冲区
                            if (this.bufferIndex > 0) {
                                const finalBuffer = this.buffer.slice(0, this.bufferIndex);
                                this.port.postMessage({
                                    type: 'buffer',
                                    buffer: finalBuffer
                                });
                                this.bufferIndex = 0;
                            }

                            this.port.postMessage({ type: 'status', status: 'stopped' });
                        }
                    };
                }

                process(inputs, outputs, parameters) {
                    if (!this.isRecording) return true;

                    const input = inputs[0][0]; // 获取第一个输入通道
                    if (!input) return true;

                    // 将浮点采样转换为16位整数并存储
                    for (let i = 0; i < input.length; i++) {
                        if (this.bufferIndex >= this.frameSize) {
                            // 缓冲区已满，发送给主线程并重置
                            this.port.postMessage({
                                type: 'buffer',
                                buffer: this.buffer.slice(0)
                            });
                            this.bufferIndex = 0;
                        }

                        // 转换为16位整数 (-32768到32767)
                        this.buffer[this.bufferIndex++] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                    }

                    return true;
                }
            }

            registerProcessor('audio-recorder-processor', AudioRecorderProcessor);
        `;

        // 创建音频处理器
        async function createAudioProcessor() {
            audioContext = getAudioContextInstance();

            try {
                // 检查是否支持AudioWorklet
                if (audioContext.audioWorklet) {
                    // 注册音频处理器
                    const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
                    const url = URL.createObjectURL(blob);
                    await audioContext.audioWorklet.addModule(url);
                    URL.revokeObjectURL(url);

                    // 创建音频处理节点
                    const audioProcessor = new AudioWorkletNode(audioContext, 'audio-recorder-processor');

                    // 设置音频处理消息处理
                    audioProcessor.port.onmessage = (event) => {
                        if (event.data.type === 'buffer') {
                            // 收到PCM缓冲区数据
                            processPCMBuffer(event.data.buffer);
                        }
                    };

                    log('使用AudioWorklet处理音频', 'success');
                    return { node: audioProcessor, type: 'worklet' };
                } else {
                    // 使用旧版ScriptProcessorNode作为回退方案
                    log('AudioWorklet不可用，使用ScriptProcessorNode作为回退方案', 'warning');

                    const frameSize = 4096; // ScriptProcessorNode缓冲区大小
                    const scriptProcessor = audioContext.createScriptProcessor(frameSize, 1, 1);

                    // 将audioProcess事件设置为处理音频数据
                    scriptProcessor.onaudioprocess = (event) => {
                        if (!isRecording) return;

                        const input = event.inputBuffer.getChannelData(0);
                        const buffer = new Int16Array(input.length);

                        // 将浮点数据转换为16位整数
                        for (let i = 0; i < input.length; i++) {
                            buffer[i] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                        }

                        // 处理PCM数据
                        processPCMBuffer(buffer);
                    };

                    // 需要连接输出，否则不会触发处理
                    // 我们创建一个静音通道
                    const silent = audioContext.createGain();
                    silent.gain.value = 0;
                    scriptProcessor.connect(silent);
                    silent.connect(audioContext.destination);

                    return { node: scriptProcessor, type: 'processor' };
                }
            } catch (error) {
                log(`创建音频处理器失败: ${error.message}，尝试回退方案`, 'error');

                // 最后回退方案：使用ScriptProcessorNode
                try {
                    const frameSize = 4096; // ScriptProcessorNode缓冲区大小
                    const scriptProcessor = audioContext.createScriptProcessor(frameSize, 1, 1);

                    scriptProcessor.onaudioprocess = (event) => {
                        if (!isRecording) return;

                        const input = event.inputBuffer.getChannelData(0);
                        const buffer = new Int16Array(input.length);

                        for (let i = 0; i < input.length; i++) {
                            buffer[i] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
                        }

                        processPCMBuffer(buffer);
                    };

                    const silent = audioContext.createGain();
                    silent.gain.value = 0;
                    scriptProcessor.connect(silent);
                    silent.connect(audioContext.destination);

                    log('使用ScriptProcessorNode作为回退方案成功', 'warning');
                    return { node: scriptProcessor, type: 'processor' };
                } catch (fallbackError) {
                    log(`回退方案也失败: ${fallbackError.message}`, 'error');
                    return null;
                }
            }
        }

        // 初始化直接从PCM数据录音的系统
        let audioProcessor = null;
        let audioProcessorType = null;
        let audioSource = null;

        // 处理PCM缓冲数据
        let pcmDataBuffer = new Int16Array();

        function processPCMBuffer(buffer) {
            if (!isRecording) return;

            // 将新的PCM数据追加到缓冲区
            const newBuffer = new Int16Array(pcmDataBuffer.length + buffer.length);
            newBuffer.set(pcmDataBuffer);
            newBuffer.set(buffer, pcmDataBuffer.length);
            pcmDataBuffer = newBuffer;

            // 检查是否有足够的数据进行Opus编码（16000Hz, 60ms = 960个采样点）
            const samplesPerFrame = 960; // 60ms @ 16kHz

            while (pcmDataBuffer.length >= samplesPerFrame) {
                // 从缓冲区取出一帧数据
                const frameData = pcmDataBuffer.slice(0, samplesPerFrame);
                pcmDataBuffer = pcmDataBuffer.slice(samplesPerFrame);

                // 编码为Opus
                encodeAndSendOpus(frameData);
            }
        }

        // 编码并发送Opus数据
        function encodeAndSendOpus(pcmData = null) {
            if (!opusEncoder) {
                log('Opus编码器未初始化', 'error');
                return;
            }

            try {
                // 如果提供了PCM数据，则编码该数据
                if (pcmData) {
                    // 使用已初始化的Opus编码器编码
                    const opusData = opusEncoder.encode(pcmData);

                    if (opusData && opusData.length > 0) {
                        // 存储音频帧
                        audioBuffers.push(opusData.buffer);
                        totalAudioSize += opusData.length;

                        // 如果WebSocket已连接，则发送数据
                        if (websocket && websocket.readyState === WebSocket.OPEN) {
                            try {
                                // 服务端期望接收原始Opus数据，不需要任何额外包装
                                websocket.send(opusData.buffer);
                                log(`发送Opus帧，大小：${opusData.length}字节`, 'debug');
                            } catch (error) {
                                log(`WebSocket发送错误: ${error.message}`, 'error');
                            }
                        }
                    } else {
                        log('Opus编码失败，无有效数据返回', 'error');
                    }
                } else {
                    // 处理剩余的PCM数据
                    if (pcmDataBuffer.length > 0) {
                        // 如果剩余的采样点不足一帧，用静音填充
                        const samplesPerFrame = 960;
                        if (pcmDataBuffer.length < samplesPerFrame) {
                            const paddedBuffer = new Int16Array(samplesPerFrame);
                            paddedBuffer.set(pcmDataBuffer);
                            // 剩余部分为0（静音）
                            encodeAndSendOpus(paddedBuffer);
                        } else {
                            encodeAndSendOpus(pcmDataBuffer.slice(0, samplesPerFrame));
                        }
                        pcmDataBuffer = new Int16Array(0);
                    }
                }
            } catch (error) {
                log(`Opus编码错误: ${error.message}`, 'error');
            }
        }

        // 开始直接从PCM数据录音
        async function startDirectRecording() {
            if (isRecording) return;

            try {
                // 初始化Opus编码器
                if (!initOpusEncoder()) {
                    log('无法启动录音: Opus编码器初始化失败', 'error');
                    return;
                }

                // 请求麦克风权限
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,
                        channelCount: 1
                    }
                });

                // 创建音频上下文和分析器
                audioContext = getAudioContextInstance();

                // 创建音频处理器
                const processorResult = await createAudioProcessor();
                if (!processorResult) {
                    log('无法创建音频处理器', 'error');
                    return;
                }

                audioProcessor = processorResult.node;
                audioProcessorType = processorResult.type;

                // 连接音频处理链
                audioSource = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;

                audioSource.connect(analyser);
                audioSource.connect(audioProcessor);

                // 启动录音
                pcmDataBuffer = new Int16Array();
                audioBuffers = [];
                totalAudioSize = 0;
                isRecording = true;

                // 启动音频处理器的录音 - 只有AudioWorklet才需要发送消息
                if (audioProcessorType === 'worklet' && audioProcessor.port) {
                    audioProcessor.port.postMessage({ command: 'start' });
                }

                // 发送监听开始消息
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    // 使用与服务端期望的listen消息格式
                    const listenMessage = {
                        type: 'listen',
                        mode: 'manual',  // 使用手动模式，由我们控制开始/停止
                        state: 'start'   // 表示开始录音
                    };

                    log(`发送录音开始消息: ${JSON.stringify(listenMessage)}`, 'info');
                    websocket.send(JSON.stringify(listenMessage));
                } else {
                    log('WebSocket未连接，无法发送开始消息', 'error');
                    return false;
                }

                // 开始音频可视化
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                drawVisualizer(dataArray);

                // 在UI上显示录音计时器
                let recordingSeconds = 0;
                const recordingTimer = setInterval(() => {
                    recordingSeconds += 0.1;
                    recordButton.textContent = `停止录音 ${recordingSeconds.toFixed(1)}秒`;
                }, 100);

                // 保存计时器，以便在停止时清除
                window.recordingTimer = recordingTimer;

                recordButton.classList.add('recording');
                recordButton.disabled = false;

                log('开始PCM直接录音', 'success');
                return true;
            } catch (error) {
                log(`直接录音启动错误: ${error.message}`, 'error');
                isRecording = false;
                return false;
            }
        }

        // 停止直接从PCM数据录音
        function stopDirectRecording() {
            if (!isRecording) return;

            try {
                // 停止录音
                isRecording = false;

                // 停止音频处理器的录音
                if (audioProcessor) {
                    // 只有AudioWorklet才需要发送停止消息
                    if (audioProcessorType === 'worklet' && audioProcessor.port) {
                        audioProcessor.port.postMessage({ command: 'stop' });
                    }

                    audioProcessor.disconnect();
                    audioProcessor = null;
                }

                // 断开音频连接
                if (audioSource) {
                    audioSource.disconnect();
                    audioSource = null;
                }

                // 停止可视化
                if (visualizationRequest) {
                    cancelAnimationFrame(visualizationRequest);
                    visualizationRequest = null;
                }

                // 清除录音计时器
                if (window.recordingTimer) {
                    clearInterval(window.recordingTimer);
                    window.recordingTimer = null;
                }

                // 编码并发送剩余的数据
                encodeAndSendOpus();

                // 发送一个空的消息作为结束标志（模拟接收到空音频数据的情况）
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    // 使用空的Uint8Array发送最后一个空帧
                    const emptyOpusFrame = new Uint8Array(0);
                    websocket.send(emptyOpusFrame);

                    // 发送监听结束消息
                    const stopMessage = {
                        type: 'listen',
                        mode: 'manual',
                        state: 'stop'
                    };

                    websocket.send(JSON.stringify(stopMessage));
                    log('已发送录音停止信号', 'info');
                }

                // 重置UI
                recordButton.textContent = '开始录音';
                recordButton.classList.remove('recording');
                recordButton.disabled = false;

                log('停止PCM直接录音', 'success');
                return true;
            } catch (error) {
                log(`直接录音停止错误: ${error.message}`, 'error');
                return false;
            }
        }

        async function handleBinaryMessage(data) {
            try {
                let arrayBuffer;
                // 根据数据类型进行处理
                if (data instanceof ArrayBuffer) {
                    arrayBuffer = data;
                    log(`收到ArrayBuffer音频数据，大小: ${data.byteLength}字节`, 'debug');
                } else if (data instanceof Blob) {
                    // 如果是Blob类型，转换为ArrayBuffer
                    arrayBuffer = await data.arrayBuffer();
                    log(`收到Blob音频数据，大小: ${arrayBuffer.byteLength}字节`, 'debug');
                } else {
                    log(`收到未知类型的二进制数据: ${typeof data}`, 'warning');
                    return;
                }
                // 创建Uint8Array用于处理
                const opusData = new Uint8Array(arrayBuffer);
                if (opusData.length > 0) {
                    // 将数据添加到缓冲队列
                    queue.enqueue(opusData);
                } else {
                    log('收到空音频数据帧，可能是结束标志', 'warning');
                    // 如果正在播放，发送结束信号
                    if (isAudioPlaying && streamingContext) {
                        streamingContext.endOfStream = true;
                    }
                }
            } catch (error) {
                log(`处理二进制消息出错: ${error.message}`, 'error');
            }
        }

        // 获取配置值
        function getConfig() {
            const deviceMac = document.getElementById('deviceMac').value.trim();
            return {
                deviceId: deviceMac,  // 使用MAC地址作为deviceId
                deviceName: document.getElementById('deviceName').value.trim(),
                deviceMac: deviceMac,
                clientId: document.getElementById('clientId').value.trim(),
                token: document.getElementById('token').value.trim()
            };
        }

        initApp();
        
        // 页面加载完成后运行兼容性检查
        document.addEventListener('DOMContentLoaded', function() {
            // 延迟一点时间确保页面完全加载
            setTimeout(() => {
                checkBrowserCompatibility();
            }, 1000);
        });
    </script>
</body>

</html>